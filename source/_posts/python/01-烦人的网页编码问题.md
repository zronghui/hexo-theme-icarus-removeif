---
title: 烦人的网页编码问题
toc: true
recommend: 1
uniqueId: '2020-03-01 02:31:44/"烦人的网页编码问题".html'
date: 2020-03-01 10:31:44
thumbnail:
categories:
- python
tags:
keywords:
---

[TOC]

<!--more-->

请求网址乱码：

一开始以为是压缩问题：

## content-encoding 和 accept-encoding

- response headers中的content-encoding
- request headers 中的accept-encoding

content-encoding是指网页使用了哪种压缩方式传输数据给你，accept-encoding表示你发送请求时告诉服务器，我可以解压这些格式的数据。

二者的关系是，对方网页会根据你发送的accept-encoding来决定用什么格式(content-encoding)传给你。

Python 中，若不添加 accept-encoding, requests 默认添加 r.request.headers['Accept-Encoding'] 为 'gzip, deflate'

若 'Accept-Encoding': ''，则 response 应该没有压缩

```python
headers = {
    'Accept-Encoding': '',
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36'
}
r = requests.get('https://zhuanlan.zhihu.com/python-programming', headers = headers)
>>> r.headers['Content-Encoding']
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
  File "C:\Program Files\Anaconda3\lib\site-packages\requests\structures.py", line 54, in __getitem__
    return self._store[key.lower()][1]
KeyError: 'content-encoding'
```



## 获取网页正确编码

requests会从服务器返回的响应头的 Content-Type 去获取字符集编码，如果content-type有charset字段那么requests才能正确识别编码，否则就使用默认的 ISO-8859-1

所以 requests 的 response.text 有可能是乱码的

```python
ic(doc.headers, chardet.detect(doc.content), doc.apparent_encoding, doc.encoding)
# ic| doc.headers: {'Content-Type': 'text/html', 'Last-Modified': 'Sun, 01 Mar 2020 00:49:50 GMT', 'Vary': 'Accept-Encoding', 'ETag': 'W/"5e5b06ae-1da6a"', 'Expires': 'Sun, 01 Mar 2020 02:44:33 GMT', 'Cache-Control': 'max-age=300', 'P3P': 'CP=CAO PSA OUR', 'Content-Encoding': 'gzip', 'Content-Length': '25940', 'Accept-Ranges': 'bytes', 'Date': 'Sun, 01 Mar 2020 02:44:01 GMT', 'Age': '267', 'Connection': 'keep-alive', 'X-Hits': '4'}
#     chardet.detect(doc.content): {'confidence': 0.99, 'encoding': 'GB2312', 'language': 'Chinese'}
#     doc.apparent_encoding: 'GB2312'
#     doc.encoding: 'ISO-8859-1'
```



## 查看网页正确编码的方法

response.apparent_encoding 或者 chardet.detect(response.content)

requests的返回结果对象里有个apparent_encoding函数, apparent_encoding通过调用chardet.detect()来识别文本编码. 但是需要注意的是，这有些消耗计算资源.

正确的编码还可能存在于 meta 中

```html
<meta http-equiv="Content-Type" content="text/html; charset=gbk" />
```

python requests的utils.py里已经有个完善的从html中获取meta charset的函数. 说白了还是一对的正则表达式.

```python
In [32]: requests.utils.get_encodings_from_content(r.content)
Out[32]: ['gbk']
```



总之，网页乱码的情况下，可以用 response.apparent_encoding 获取正确编码xx，再用 response.encoding = 'xx' , 然后就能调用 response.text

## 参考文章

[Headers设置之Accept-Encoding - 知乎](https://zhuanlan.zhihu.com/p/35643926)
[代码分析Python requests库中文编码问题 – 峰云就她了](http://xiaorui.cc/archives/2786)
